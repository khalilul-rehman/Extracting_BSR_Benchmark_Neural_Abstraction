{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b1f563-04e5-4687-93f5-bfe01acb7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d168980d-3a06-4336-8ebd-4c3aa75c4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QuadraticConstraintModel import get_leaf_samples\n",
    "\n",
    "from QuadraticConstraintModel import constrained_optimization_gurobi\n",
    "\n",
    "from QuadraticConstraintModel import predict_from_COF\n",
    "\n",
    "from QuadraticConstraintModel import  get_h_from_COF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffc5904-e58b-40d2-8d98-42050d9224fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load DataSet\n",
    "def load_dataset(file_path, num_attributes=2, num_classes=2):\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.iloc[:, 0 :  num_attributes].values\n",
    "    y = data.iloc[:,  num_attributes:  num_attributes + num_classes].values\n",
    "    # y = data.iloc[:, 9:10].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01ee8741-38e5-4bf0-9d02-02a4ab023b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_root_mean_square_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the Normalized Root Mean Square Error (NRMSE) between y_true and y_pred.\n",
    "    If the range of y_true is zero, it normalizes by the number of samples * outputs.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (np.ndarray): Ground truth values, shape (n_samples, n_outputs)\n",
    "        y_pred (np.ndarray): Predicted values, shape (n_samples, n_outputs)\n",
    "\n",
    "    Returns:\n",
    "        float: NRMSE value\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    \n",
    "    # Compute range\n",
    "    y_range = np.max(y_true) - np.min(y_true)\n",
    "    \n",
    "    if y_range != 0:\n",
    "        # Normalize by range\n",
    "        return rmse / y_range\n",
    "    else:\n",
    "        # Normalize by n_samples * n_outputs\n",
    "        n_samples, n_outputs = y_true.shape\n",
    "        return np.sqrt(np.sum((y_true - y_pred) ** 2) / (n_samples * n_outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb8b22c9-6e80-4189-abdf-32e194218f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_leaf(leaf_id, indices, X_train, y_train, feature_names, optimizer):\n",
    "    X_leaf = X_train[indices]\n",
    "    y_leaf = y_train[indices]\n",
    "    \n",
    "    # Choose optimizer\n",
    "    if optimizer == \"gurobi\":\n",
    "        M, m0, h = constrained_optimization_gurobi(X_leaf, y_leaf)\n",
    "    elif optimizer == \"gurobi_MSE\":\n",
    "        M, m0, h = constrained_optimization_MSE_gurobi(X_leaf, y_leaf)\n",
    "    elif optimizer == \"least_squares\":\n",
    "        M, m0, h = least_squares_solution(X_leaf, y_leaf)\n",
    "    elif optimizer == \"gurobi_l2\":\n",
    "        # print(\"Optimizing with L2 regularization\")\n",
    "        M, m0, h = constrained_optimization_regularization_gurobi(X_leaf, y_leaf)\n",
    "    elif optimizer == \"gurobi_MSE_l2\":\n",
    "        # print(\"Optimizing with MSE L2 regularization\")\n",
    "        M, m0, h = constrained_optimization_MSE_regularization_gurobi(X_leaf, y_leaf)\n",
    "    else:\n",
    "        M, m0, h = constrained_optimization(X_leaf, y_leaf)\n",
    "    \n",
    "    # Build model info\n",
    "    model = {\n",
    "        \"leaf_id\": leaf_id,\n",
    "        \"CO_Model\": {'M': M, 'm0': m0, 'h': h},\n",
    "        \"no_samples\": len(indices),\n",
    "        \"indices\": indices,\n",
    "        \"bounds\": {\n",
    "            feature_names[i]: (X_leaf[:, i].min(), X_leaf[:, i].max())\n",
    "            for i in range(X_leaf.shape[1])\n",
    "        }\n",
    "    }\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_COF_on_leaves_parallel(X_train, y_train, tree, feature_names=None, optimizer=\"gurobi\", n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Train constrained optimization models on tree leaves in parallel.\n",
    "\n",
    "    Parameters:\n",
    "        X_train, y_train : np.ndarray\n",
    "        tree : fitted sklearn tree\n",
    "        feature_names : list of feature names (optional)\n",
    "        optimizer : {\"gurobi\", \"CVXPY + SCS\"}\n",
    "        n_jobs : number of parallel workers (-1 = all cores)\n",
    "    \"\"\"\n",
    "    leaf_samples = get_leaf_samples(tree, X_train)\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "    # Run leaf computations in parallel\n",
    "    tree_extracted_info = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_leaf)(leaf_id, indices, X_train, y_train, feature_names, optimizer)\n",
    "        for leaf_id, indices in leaf_samples.items()\n",
    "    )\n",
    "\n",
    "    return tree_extracted_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b0dcd42-ad5a-452f-937c-42a7f0d7bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_name = \"navigation_old\"\n",
    "n_samples = 500000\n",
    "X, y = load_dataset(f\"Dataset/{sys_name}/{sys_name}_{n_samples}/data_{sys_name}_{n_samples}.csv\",num_attributes=4, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22bbd20f-efde-453b-9c99-05cff69ff0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1892 ,  2.4081 , -0.49971, -0.74031],\n",
       "       [ 1.7434 ,  1.0898 , -0.10954, -0.41258],\n",
       "       [ 1.0537 ,  0.13005,  0.93942, -0.14472],\n",
       "       ...,\n",
       "       [ 2.4862 ,  1.4989 , -0.75639,  0.54465],\n",
       "       [ 1.352  ,  0.87072, -0.68432, -0.90102],\n",
       "       [ 2.4397 ,  2.1971 , -0.22278, -0.79128]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36307310-a932-4e33-b6fb-8fef65c6613c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1451 ,  2.3306 , -0.44092, -0.77409],\n",
       "       [ 1.7419 ,  1.0445 , -0.01462, -0.45312],\n",
       "       [ 1.1482 ,  0.11716,  0.94498, -0.1289 ],\n",
       "       ...,\n",
       "       [ 2.4205 ,  1.5353 , -0.65719,  0.36334],\n",
       "       [ 1.3018 ,  0.78931, -0.50192, -0.81411],\n",
       "       [ 2.4202 ,  2.1154 , -0.19575, -0.81685]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81f23ada-a13d-4edb-93f6-9c15b54f9348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X_Training = (249999, 4) \n",
      " Shape of X_Testing = (250000, 4)\n",
      " Shape of Y_Training = (249999, 4) \n",
      " Shape of Y_Testing = (250000, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.5)\n",
    "print(f\" Shape of X_Training = {X_train.shape} \\n Shape of X_Testing = {X_test.shape}\")\n",
    "print(f\" Shape of Y_Training = {y_train.shape} \\n Shape of Y_Testing = {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a35c7-b41c-45a6-8551-64f34936528f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a048179f-9348-46e6-8890-bff586e8d945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2658eb7-63bb-4471-b578-8252e8ea1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional, List\n",
    "\n",
    "class _Node:\n",
    "    def __init__(self, depth: int = 0):\n",
    "        self.depth = depth\n",
    "        self.is_leaf = True\n",
    "        self.feature: Optional[int] = None\n",
    "        self.threshold: Optional[float] = None\n",
    "        self.left: Optional[int] = None\n",
    "        self.right: Optional[int] = None\n",
    "        self.n_samples: int = 0\n",
    "        self.value: Optional[np.ndarray] = None\n",
    "        self.mse: float = 0.0\n",
    "        self.idx: Optional[np.ndarray] = None  # keep track of samples reaching this node\n",
    "        self.leaf_id: Optional[int] = None     # assign after pruning\n",
    "\n",
    "class CustomDecisionTreeRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: Optional[int] = None,\n",
    "        min_samples_split: int = 2,\n",
    "        mse_threshold: float = 1e-7,\n",
    "        min_improvement: float = 1e-7,\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.mse_threshold = mse_threshold\n",
    "        self.min_improvement = min_improvement\n",
    "\n",
    "        self.n_features_in_: Optional[int] = None\n",
    "        self.n_outputs_: Optional[int] = None\n",
    "        self._nodes: List[_Node] = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _mse(sum_y: np.ndarray, sum_y2: float, n: int) -> float:\n",
    "        if n <= 0:\n",
    "            return 0.0\n",
    "        return float((sum_y2 - float(np.sum(sum_y ** 2)) / n) / n)\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "        self._nodes = []\n",
    "        self._build_node(X, y, np.arange(X.shape[0]), depth=0)\n",
    "        self._assign_leaf_ids()\n",
    "        self._fitted_X = X\n",
    "        self._fitted_y = y\n",
    "        return self\n",
    "\n",
    "    def _build_node(self, X, y, idx, depth):\n",
    "        node_id = len(self._nodes)\n",
    "        node = _Node(depth=depth)\n",
    "        self._nodes.append(node)\n",
    "\n",
    "        Y = y[idx]\n",
    "        n_node = Y.shape[0]\n",
    "        sum_y = Y.sum(axis=0)\n",
    "        sum_y2 = float((Y ** 2).sum())\n",
    "\n",
    "        node.n_samples = n_node\n",
    "        node.value = sum_y / max(n_node, 1)\n",
    "        node.mse = self._mse(sum_y, sum_y2, n_node)\n",
    "        node.idx = idx\n",
    "\n",
    "        stop_by_depth = (self.max_depth is not None and depth >= self.max_depth)\n",
    "        if n_node < self.min_samples_split or stop_by_depth or node.mse <= self.mse_threshold:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "\n",
    "        best = self._best_split(X, y, idx, sum_y, sum_y2, n_node)\n",
    "        if best is None:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "\n",
    "        feat, thr, left_idx, right_idx, mse_left, mse_right = best\n",
    "        parent_mse = node.mse\n",
    "        n_left, n_right = left_idx.size, right_idx.size\n",
    "        weighted_child_mse = (n_left * mse_left + n_right * mse_right) / n_node\n",
    "        gain = parent_mse - weighted_child_mse\n",
    "\n",
    "        if gain <= self.min_improvement:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "\n",
    "        node.is_leaf = False\n",
    "        node.feature = int(feat)\n",
    "        node.threshold = float(thr)\n",
    "        node.left = self._build_node(X, y, left_idx, depth + 1)\n",
    "        node.right = self._build_node(X, y, right_idx, depth + 1)\n",
    "        return node_id\n",
    "\n",
    "    def _best_split(self, X, y, idx, sum_y, sum_y2, n_node):\n",
    "        X_node = X[idx]\n",
    "        Y_node = y[idx]\n",
    "        total_sum_y = sum_y\n",
    "        total_sum_y2 = sum_y2\n",
    "        parent_mse = self._mse(total_sum_y, total_sum_y2, n_node)\n",
    "\n",
    "        best_feat = None\n",
    "        best_thr = None\n",
    "        best_left_idx = None\n",
    "        best_right_idx = None\n",
    "        best_mse_left = None\n",
    "        best_mse_right = None\n",
    "\n",
    "        for f in range(self.n_features_in_):\n",
    "            x = X_node[:, f]\n",
    "            order = np.argsort(x, kind=\"mergesort\")\n",
    "            x_sorted = x[order]\n",
    "            Y_sorted = Y_node[order]\n",
    "\n",
    "            diffs = x_sorted[1:] - x_sorted[:-1]\n",
    "            valid = diffs != 0.0\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            csum_y = np.cumsum(Y_sorted, axis=0)\n",
    "            row_sq = np.einsum(\"ij,ij->i\", Y_sorted, Y_sorted)\n",
    "            csum_y2 = np.cumsum(row_sq)\n",
    "            split_positions = np.nonzero(valid)[0]\n",
    "\n",
    "            left_n = (split_positions + 1).astype(np.int64)\n",
    "            right_n = n_node - left_n\n",
    "            left_sum_y = csum_y[split_positions]\n",
    "            right_sum_y = total_sum_y - left_sum_y\n",
    "            left_sum_y2 = csum_y2[split_positions]\n",
    "            right_sum_y2 = total_sum_y2 - left_sum_y2\n",
    "\n",
    "            left_mse = (left_sum_y2 - np.sum(left_sum_y ** 2, axis=1) / left_n) / left_n\n",
    "            right_mse = (right_sum_y2 - np.sum(right_sum_y ** 2, axis=1) / right_n) / right_n\n",
    "            weighted_child_mse = (left_n * left_mse + right_n * right_mse) / n_node\n",
    "\n",
    "            best_pos = int(np.argmin(weighted_child_mse))\n",
    "            candidate_mse = float(weighted_child_mse[best_pos])\n",
    "            if candidate_mse >= parent_mse:\n",
    "                continue\n",
    "\n",
    "            i = split_positions[best_pos]\n",
    "            thr = 0.5 * (x_sorted[i] + x_sorted[i + 1])\n",
    "            mask_left = x <= thr\n",
    "            left_idx = idx[mask_left]\n",
    "            right_idx = idx[~mask_left]\n",
    "            if left_idx.size == 0 or right_idx.size == 0:\n",
    "                continue\n",
    "\n",
    "            if best_thr is None or candidate_mse < (best_mse_left + best_mse_right if best_mse_left is not None else np.inf):\n",
    "                best_feat = f\n",
    "                best_thr = thr\n",
    "                best_mse_left = float(left_mse[best_pos])\n",
    "                best_mse_right = float(right_mse[best_pos])\n",
    "                best_left_idx = left_idx\n",
    "                best_right_idx = right_idx\n",
    "\n",
    "        if best_thr is None:\n",
    "            return None\n",
    "        return best_feat, best_thr, best_left_idx, best_right_idx, best_mse_left, best_mse_right\n",
    "\n",
    "    # --------------------\n",
    "    # Least squares & pruning by h\n",
    "    # --------------------\n",
    "    def _least_squares_solution(self, X_leaf, y_leaf):\n",
    "        n_samples, n_features = X_leaf.shape\n",
    "        X_aug = np.hstack([np.ones((n_samples, 1)), X_leaf])\n",
    "        XtX = X_aug.T @ X_aug\n",
    "        XtY = X_aug.T @ y_leaf\n",
    "        Theta = np.linalg.pinv(XtX) @ XtY\n",
    "        m0 = Theta[0, :]\n",
    "        M = Theta[1:, :].T\n",
    "        Y_hat = X_aug @ Theta\n",
    "        residuals = y_leaf - Y_hat\n",
    "        h_val = np.sum(residuals ** 2)\n",
    "        return M, m0, h_val\n",
    "\n",
    "    def prune_by_h(self, X, y, h_threshold: float = 0.1):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        def _prune_recursive(node_id):\n",
    "            node = self._nodes[node_id]\n",
    "            if node.is_leaf:\n",
    "                return node.idx\n",
    "            left_idx = _prune_recursive(node.left)\n",
    "            right_idx = _prune_recursive(node.right)\n",
    "            combined_idx = np.concatenate([left_idx, right_idx])\n",
    "            _, _, combined_h = self._least_squares_solution(X[combined_idx], y[combined_idx])\n",
    "            # prune if h <= h_threshold\n",
    "            if combined_h <= h_threshold:\n",
    "                node.is_leaf = True\n",
    "                node.left = None\n",
    "                node.right = None\n",
    "                node.idx = combined_idx\n",
    "                node.value = y[combined_idx].mean(axis=0)\n",
    "            return node.idx if node.is_leaf else combined_idx\n",
    "\n",
    "        _prune_recursive(0)\n",
    "        self._assign_leaf_ids()\n",
    "\n",
    "    # --------------------\n",
    "    # Assign leaf IDs\n",
    "    # --------------------\n",
    "    def _assign_leaf_ids(self):\n",
    "        counter = 0\n",
    "        for node in self._nodes:\n",
    "            if node.is_leaf:\n",
    "                node.leaf_id = counter\n",
    "                counter += 1\n",
    "\n",
    "    # --------------------\n",
    "    # Prediction\n",
    "    # --------------------\n",
    "    def predict_row(self, x):\n",
    "        node_id = 0\n",
    "        while not self._nodes[node_id].is_leaf:\n",
    "            node = self._nodes[node_id]\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                node_id = node.left\n",
    "            else:\n",
    "                node_id = node.right\n",
    "        return self._nodes[node_id].value\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return np.vstack([self.predict_row(row) for row in X])\n",
    "\n",
    "    # ---------------------------\n",
    "    # Node stats\n",
    "    # ---------------------------\n",
    "    def print_node_sse(self):\n",
    "        for i, node in enumerate(self._nodes):\n",
    "            print(f\"Node {i}, depth {node.depth}, samples {node.n_samples}, scaled SSE {node.sse:.6f}, leaf {node.is_leaf}\")\n",
    "\n",
    "    def count_nodes(self):\n",
    "        return len(self._nodes)\n",
    "\n",
    "    def count_leaves(self):\n",
    "        return sum(1 for n in self._nodes if n.is_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95ffe20b-bc5e-4633-bc08-0ac4de3d6eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (first 5): [[ 1.2978      2.9458      0.86112     0.69014   ]\n",
      " [ 0.1547      0.68649    -0.49733    -0.38349   ]\n",
      " [ 2.33363333  2.10146667  0.54932667 -0.63284333]\n",
      " [ 1.31876     2.43455    -0.06256525  0.56483   ]\n",
      " [ 0.43283     1.2009     -0.655      -0.53837   ]]\n",
      "Number of nodes: 152599\n",
      "Number of leaves: 76300\n"
     ]
    }
   ],
   "source": [
    "# Train custom tree\n",
    "tree = CustomDecisionTreeRegressor(mse_threshold=1.0)\n",
    "tree.fit(X_train, y_train)\n",
    "#tree.print_node_mse()\n",
    "\n",
    "print(\"Predictions (first 5):\", tree.predict(X_test[:5]))\n",
    "print(\"Number of nodes:\", tree.count_nodes())\n",
    "print(\"Number of leaves:\", tree.count_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77437afd-de4a-4dfb-a3b2-d99d558b7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.prune_by_h(X_train, y_train, h_threshold=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5af7af64-2c62-4622-934c-2a0e83defe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (first 5): [[ 1.51231077  1.57459948  0.10930605  0.63443242]\n",
      " [ 1.08754056  1.13436    -0.01604778 -0.40725111]\n",
      " [ 1.58313604  1.50502192  0.11609518 -0.61576879]\n",
      " [ 1.39630515  1.34144703  0.05051873  0.54887167]\n",
      " [ 1.52160816  1.46163879  0.06171542 -0.47212175]]\n",
      "Number of nodes: 152599\n",
      "Number of leaves: 151604\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions (first 5):\", tree.predict(X_test[:5]))\n",
    "print(\"Number of nodes:\", tree.count_nodes())\n",
    "print(\"Number of leaves:\", tree.count_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e364f-ba75-498e-8b73-8095f8447a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5d110-b28c-4097-89b8-24945705f019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "764cf700-1483-4d95-989b-8caca1b2fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_prune_COF_tree_v3(\n",
    "    X_train, y_train, X_test=None, y_test=None,\n",
    "    initial_tree_params=None, optimizer=\"gurobi\",\n",
    "    alpha=1e-6, h_min=0, ignore_h=False, n_jobs=-1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a decision tree, build COF models, and prune tree sequentially.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1️⃣ Train initial tree\n",
    "    # -------------------------------\n",
    "    if initial_tree_params is None:\n",
    "        initial_tree_params = {\"max_depth\": 5}\n",
    "\n",
    "    tree = DecisionTreeRegressor(**initial_tree_params)\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2️⃣ Build COF models for leaves in parallel\n",
    "    # -------------------------------\n",
    "    COF_model_tree = train_COF_on_leaves_parallel(\n",
    "        X_train, y_train, tree, optimizer=optimizer, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    leaf_nodes = np.where(children_left == -1)[0]\n",
    "\n",
    "    leaf_h_dict = {leaf: COF_model_tree[i]['CO_Model']['h'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_indices_dict = {leaf: COF_model_tree[i]['indices'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_COFS_dict = {leaf: COF_model_tree[i] for i, leaf in enumerate(leaf_nodes)}\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3️⃣ Helper function: compute COF\n",
    "    # -------------------------------\n",
    "    def compute_h_and_COF(indices):\n",
    "        \"\"\"\n",
    "        Returns h, M, m0 for given indices using optimizer\n",
    "        \"\"\"\n",
    "        if ignore_h:\n",
    "            return 0, np.zeros((1, X_train.shape[1])), np.zeros(1)\n",
    "\n",
    "        if optimizer == \"gurobi\":\n",
    "            M, m0, h = constrained_optimization_gurobi(X_train[indices], y_train[indices])\n",
    "        elif optimizer == \"gurobi_MSE\":\n",
    "            M, m0, h = constrained_optimization_MSE_gurobi(X_train[indices], y_train[indices])\n",
    "        else:\n",
    "            M, m0, h = constrained_optimization(X_train[indices], y_train[indices])\n",
    "\n",
    "        return h, M, m0\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4️⃣ Sequential pruning function\n",
    "    # -------------------------------\n",
    "    def prune_node(node):\n",
    "        left = children_left[node]\n",
    "        right = children_right[node]\n",
    "\n",
    "        # Leaf node\n",
    "        if left == -1 and right == -1:\n",
    "            return leaf_h_dict[node], 1, leaf_indices_dict[node], False\n",
    "\n",
    "        # Process children sequentially\n",
    "        left_cost, left_leaves, left_indices, _ = prune_node(left)\n",
    "        right_cost, right_leaves, right_indices, _ = prune_node(right)\n",
    "\n",
    "        combined_indices = np.concatenate([left_indices, right_indices])\n",
    "        subtree_cost = left_cost + right_cost\n",
    "        subtree_leaves = left_leaves + right_leaves\n",
    "\n",
    "        # Compute parent COF\n",
    "        h_parent, M_parent, m0_parent = compute_h_and_COF(combined_indices)\n",
    "        prune_cost = h_parent + alpha\n",
    "\n",
    "        # Decide pruning\n",
    "        prune_flag = (not ignore_h and h_parent < h_min) or (prune_cost <= subtree_cost)\n",
    "\n",
    "        if prune_flag:\n",
    "            # Update tree\n",
    "            children_left[node] = -1\n",
    "            children_right[node] = -1\n",
    "\n",
    "            # Remove child leaves\n",
    "            for child in [left, right]:\n",
    "                leaf_COFS_dict.pop(child, None)\n",
    "                leaf_h_dict.pop(child, None)\n",
    "                leaf_indices_dict.pop(child, None)\n",
    "\n",
    "            # Update parent leaf info\n",
    "            leaf_h_dict[node] = h_parent\n",
    "            leaf_indices_dict[node] = combined_indices\n",
    "            leaf_COFS_dict[node] = {\n",
    "                \"leaf_id\": node,\n",
    "                \"CO_Model\": {\"h\": h_parent, \"M\": M_parent, \"m0\": m0_parent},\n",
    "                \"indices\": combined_indices,\n",
    "                \"no_samples\": len(combined_indices)\n",
    "            }\n",
    "\n",
    "            # Debug printing\n",
    "            print(f\"🌳 Pruning triggered at node {node}, h={h_parent:.6f}, alpha={alpha}\")\n",
    "            print(f\"➡️ Leaf indices count: {len(combined_indices)}\")\n",
    "            print(f\"➡️ M shape: {M_parent.shape}, m0 shape: {m0_parent.shape}\")\n",
    "\n",
    "            return prune_cost, 1, combined_indices, True\n",
    "        else:\n",
    "            return subtree_cost, subtree_leaves, combined_indices, False\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5️⃣ Stats before pruning\n",
    "    # -------------------------------\n",
    "    num_leaves_before = len(leaf_nodes)\n",
    "    print(f\"Before pruning: Leaves={num_leaves_before}\")\n",
    "    print(f\"h values before pruning: {list(leaf_h_dict.values())}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6️⃣ Iterative pruning until stable\n",
    "    # -------------------------------\n",
    "    previous_leaf_count = -1\n",
    "    while True:\n",
    "        prune_node(0)\n",
    "        COF_model_tree_pruned = list(leaf_COFS_dict.values())\n",
    "        current_leaf_count = len(COF_model_tree_pruned)\n",
    "        print(f\"➡️ Current leaf count after step: {current_leaf_count}\")\n",
    "        if current_leaf_count == previous_leaf_count:\n",
    "            break\n",
    "        previous_leaf_count = current_leaf_count\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7️⃣ Stats after pruning\n",
    "    # -------------------------------\n",
    "    print(f\"After pruning: Leaves={len(COF_model_tree_pruned)}\")\n",
    "    print(f\"h values after pruning: {[leaf['CO_Model']['h'] for leaf in COF_model_tree_pruned]}\")\n",
    "\n",
    "    return tree, COF_model_tree_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f0434-aee6-4e9f-81d7-0f753ef1908a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdc545f8-562c-48dd-965d-1fc58eacec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor(max_depth=5)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=5)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d5a891b-e3e8-43e6-9cd1-454c0aa19555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter Username\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2598283\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Academic license - for non-commercial use only - expires 2025-12-11\n",
      "Before pruning: Leaves=32\n",
      "h values before pruning: [7.639983686013511, 13.568259482435836, 11.316739697470844, 0.004631580879570969, 7.086392733999269, 9.027431966788876, 0.001204644174921254, 3.3445360586360917e-06, 1.59519282466579e-06, 8.499363680072431, 0.0005755224718318917, 6.238155730806415, 14.355563020295659, 3.62558658657859e-06, 8.636524102859884, 8.737191539347705, 1.795769524896014e-05, 1.387132008456195e-06, 6.325507493610986, 1.3682805897858545e-05, 7.163782355230906, 14.816472619675963, 11.824758501423366, 7.085073779153759, 11.8755672459356, 7.130106207158423, 13.811852153074149, 1.313041013725089e-05, 3.1835314032508916e-05, 2.6187642315517684e-05, 6.584385018312005, 11.635713161514916]\n",
      "🌳 Pruning triggered at node 14, h=0.000010, alpha=2\n",
      "➡️ Leaf indices count: 17341\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered at node 35, h=0.000289, alpha=2\n",
      "➡️ Leaf indices count: 16166\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered at node 57, h=0.000110, alpha=2\n",
      "➡️ Leaf indices count: 15971\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "➡️ Current leaf count after step: 29\n",
      "➡️ Current leaf count after step: 29\n",
      "After pruning: Leaves=29\n",
      "h values after pruning: [7.639983686013511, 13.568259482435836, 11.316739697470844, 0.004631580879570969, 7.086392733999269, 9.027431966788876, 1.59519282466579e-06, 8.499363680072431, 0.0005755224718318917, 6.238155730806415, 14.355563020295659, 3.62558658657859e-06, 8.636524102859884, 8.737191539347705, 6.325507493610986, 1.3682805897858545e-05, 7.163782355230906, 14.816472619675963, 11.824758501423366, 7.085073779153759, 11.8755672459356, 7.130106207158423, 13.811852153074149, 1.313041013725089e-05, 6.584385018312005, 11.635713161514916, 1.0347578997296975e-05, 0.0002888851414702381, 0.00011035181949786929]\n"
     ]
    }
   ],
   "source": [
    "tree, COF_model =train_and_prune_COF_tree_v3(X_train, y_train, X_test=X_test, y_test=y_test, \n",
    "                                initial_tree_params=None, optimizer=\"gurobi\", \n",
    "                                alpha=2, h_min=1, ignore_h=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76b76037-01d1-459d-b2da-91d442a34289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌳 Pruning triggered on node 14, h_parent=0.000010, alpha=2\n",
      "➡️ Leaf indices count: 17341\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered on node 14, h_parent=0.000010, alpha=2\n",
      "➡️ Leaf indices count: 17341\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered on node 35, h_parent=0.000289, alpha=2\n",
      "➡️ Leaf indices count: 16166\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered on node 57, h_parent=0.000110, alpha=2\n",
      "➡️ Leaf indices count: 15971\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered on node 35, h_parent=0.000289, alpha=2\n",
      "➡️ Leaf indices count: 16166\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n",
      "🌳 Pruning triggered on node 57, h_parent=0.000110, alpha=2\n",
      "➡️ Leaf indices count: 15971\n",
      "➡️ M shape: (4, 4), m0 shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_and_prune_COF_tree_v4(\n",
    "    X_train, y_train, X_test=None, y_test=None,\n",
    "    initial_tree_params=None, optimizer=\"gurobi\",\n",
    "    alpha=1e-6, h_min=0, ignore_h=False, n_jobs=-1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train COF tree and prune bottom-up in parallel.\n",
    "    \"\"\"\n",
    "    # 1️⃣ Train initial tree\n",
    "    if initial_tree_params is None:\n",
    "        initial_tree_params = {\"max_depth\": 5}\n",
    "    tree = DecisionTreeRegressor(**initial_tree_params)\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # 2️⃣ Build COF models for leaves\n",
    "    COF_model_tree = train_COF_on_leaves_parallel(\n",
    "        X_train, y_train, tree, optimizer=optimizer, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    # 3️⃣ Leaf info mapping\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    leaf_nodes = np.where(children_left == -1)[0]\n",
    "\n",
    "    leaf_h_dict = {leaf: COF_model_tree[i]['CO_Model']['h'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_indices_dict = {leaf: COF_model_tree[i]['indices'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_COFS_dict = {leaf: COF_model_tree[i] for i, leaf in enumerate(leaf_nodes)}\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4️⃣ Bottom-up parallel pruning\n",
    "    # -------------------------------\n",
    "    def prune_subtree(node):\n",
    "        left = children_left[node]\n",
    "        right = children_right[node]\n",
    "\n",
    "        if left == -1 and right == -1:\n",
    "            # Leaf node\n",
    "            return node, leaf_h_dict[node], 1, leaf_indices_dict[node]\n",
    "\n",
    "        # Process children in parallel\n",
    "        results = Parallel(n_jobs=2)(\n",
    "            delayed(prune_subtree)(child) for child in [left, right]\n",
    "        )\n",
    "        (left_node, left_h, left_leaves, left_indices), (right_node, right_h, right_leaves, right_indices) = results\n",
    "\n",
    "        combined_indices = np.concatenate([left_indices, right_indices])\n",
    "        subtree_cost = left_h + right_h\n",
    "        subtree_leaves = left_leaves + right_leaves\n",
    "\n",
    "        # Compute parent h\n",
    "        if ignore_h:\n",
    "            h_parent = 0\n",
    "        else:\n",
    "            if optimizer == \"gurobi\":\n",
    "                _, _, h_parent = constrained_optimization_gurobi(X_train[combined_indices], y_train[combined_indices])\n",
    "            elif optimizer == \"gurobi_MSE\":\n",
    "                _, _, h_parent = constrained_optimization_MSE_gurobi(X_train[combined_indices], y_train[combined_indices])\n",
    "            else:\n",
    "                _, _, h_parent = constrained_optimization(X_train[combined_indices], y_train[combined_indices])\n",
    "\n",
    "        prune_cost = h_parent + alpha\n",
    "        prune_flag = (not ignore_h and h_parent < h_min) or (prune_cost <= subtree_cost)\n",
    "\n",
    "        if prune_flag:\n",
    "            # Prune children\n",
    "            children_left[node] = -1\n",
    "            children_right[node] = -1\n",
    "\n",
    "            # Update tree and COF info\n",
    "            tree.tree_.value[node] = np.array([[h_parent]])\n",
    "            leaf_h_dict[node] = h_parent\n",
    "            leaf_indices_dict[node] = combined_indices\n",
    "            leaf_COFS_dict[node] = {\n",
    "                \"leaf_id\": node,\n",
    "                \"CO_Model\": {\"h\": h_parent},\n",
    "                \"indices\": combined_indices,\n",
    "                \"no_samples\": len(combined_indices)\n",
    "            }\n",
    "\n",
    "            # Remove pruned children from COF dict\n",
    "            for ch in [left_node, right_node]:\n",
    "                if ch in leaf_COFS_dict:\n",
    "                    del leaf_COFS_dict[ch]\n",
    "\n",
    "            print(f\"Pruning triggered at node {node} with h={h_parent:.6f}\")\n",
    "            return node, prune_cost, 1, combined_indices\n",
    "        else:\n",
    "            return node, subtree_cost, subtree_leaves, combined_indices\n",
    "\n",
    "    # -------------------------------\n",
    "    # 5️⃣ Stats before pruning\n",
    "    # -------------------------------\n",
    "    h_values_before = list(leaf_h_dict.values())\n",
    "    num_leaves_before = len(leaf_nodes)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        nrmse_train_before = normalized_root_mean_square_error(y_train, tree.predict(X_train))\n",
    "        nrmse_test_before = normalized_root_mean_square_error(y_test, tree.predict(X_test))\n",
    "        nrmse_train_COF_before = normalized_root_mean_square_error(y_train, predict_from_COF(COF_model_tree, X_train, tree))\n",
    "        nrmse_test_COF_before = normalized_root_mean_square_error(y_test, predict_from_COF(COF_model_tree, X_test, tree))\n",
    "        print(f\"Before pruning: Leaves={num_leaves_before}, NRMSE[Tree]={nrmse_train_before:.4f}/{nrmse_test_before:.4f}, \"\n",
    "              f\"NRMSE[COF]={nrmse_train_COF_before:.4f}/{nrmse_test_COF_before:.4f}\")\n",
    "        print(f\"h values before pruning: {h_values_before}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 6️⃣ Start bottom-up pruning\n",
    "    # -------------------------------\n",
    "    prune_subtree(0)\n",
    "    COF_model_tree_pruned = list(leaf_COFS_dict.values())\n",
    "\n",
    "    # -------------------------------\n",
    "    # 7️⃣ Stats after pruning\n",
    "    # -------------------------------\n",
    "    leaf_h_dict_after = {leaf['leaf_id']: leaf['CO_Model']['h'] for leaf in COF_model_tree_pruned}\n",
    "    h_values_after = list(leaf_h_dict_after.values())\n",
    "    num_leaves_after = len(COF_model_tree_pruned)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        nrmse_train_after = normalized_root_mean_square_error(y_train, tree.predict(X_train))\n",
    "        nrmse_test_after = normalized_root_mean_square_error(y_test, tree.predict(X_test))\n",
    "        nrmse_train_COF_after = normalized_root_mean_square_error(y_train, predict_from_COF(COF_model_tree_pruned, X_train, tree))\n",
    "        nrmse_test_COF_after = normalized_root_mean_square_error(y_test, predict_from_COF(COF_model_tree_pruned, X_test, tree))\n",
    "        print(f\"After pruning: Leaves={num_leaves_after}, NRMSE[Tree]={nrmse_train_after:.4f}/{nrmse_test_after:.4f}, \"\n",
    "              f\"NRMSE[COF]={nrmse_train_COF_after:.4f}/{nrmse_test_COF_after:.4f}\")\n",
    "        print(f\"h values after pruning: {h_values_after}\")\n",
    "\n",
    "    return tree, COF_model_tree_pruned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "593a29fd-1380-45cc-9c20-04a8b60c4a17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_prune_COF_tree_v4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tree, COF_model \u001b[38;5;241m=\u001b[39m\u001b[43mtrain_and_prune_COF_tree_v4\u001b[49m(X_train, y_train, X_test\u001b[38;5;241m=\u001b[39mX_test, y_test\u001b[38;5;241m=\u001b[39my_test, \n\u001b[1;32m      2\u001b[0m                                 initial_tree_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgurobi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                 alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, h_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ignore_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_and_prune_COF_tree_v4' is not defined"
     ]
    }
   ],
   "source": [
    "tree, COF_model =train_and_prune_COF_tree_v4(X_train, y_train, X_test=X_test, y_test=y_test, \n",
    "                                initial_tree_params=None, optimizer=\"gurobi\", \n",
    "                                alpha=2, h_min=1, ignore_h=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdca94e-e062-4211-94ad-05e53be52981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f7922a-bf40-45fa-b862-d7f6bd0b4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Tuple, List, Any\n",
    "\n",
    "# Optional imports for per-leaf optimizers\n",
    "try:\n",
    "    import cvxpy as cp\n",
    "except Exception:\n",
    "    cp = None\n",
    "\n",
    "try:\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "except Exception:\n",
    "    gp = None\n",
    "    GRB = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class _Node:\n",
    "    # Split info\n",
    "    feature: int = -1\n",
    "    threshold: float = 0.0\n",
    "    left: Optional[int] = None\n",
    "    right: Optional[int] = None\n",
    "\n",
    "    # Stats\n",
    "    n_samples: int = 0\n",
    "    sum_y: Optional[np.ndarray] = None       # shape (n_outputs,)\n",
    "    sum_y2: float = 0.0                      # scalar: sum over samples of ||y||^2\n",
    "\n",
    "    # Prediction at leaf\n",
    "    value: Optional[np.ndarray] = None       # mean y, shape (n_outputs,)\n",
    "\n",
    "    # Bookkeeping\n",
    "    depth: int = 0\n",
    "    is_leaf: bool = True\n",
    "    leaf_id: Optional[int] = None\n",
    "\n",
    "    # Cached pruning metric (computed when needed)\n",
    "    _g_alpha: Optional[float] = None\n",
    "\n",
    "\n",
    "class CustomDecisionTreeRegressor:\n",
    "    \"\"\"\n",
    "    A fast, multi-output regression tree with:\n",
    "    - MSE-based splits and stopping when leaf MSE (averaged across targets) ≤ threshold\n",
    "    - max_depth stopping\n",
    "    - post-pruning via cost-complexity (ccp_alpha)\n",
    "    - min_leaf_samples enforced post-fit (does not influence split choices)\n",
    "    - per-leaf constrained optimizers (cvxpy or gurobi) with prediction\n",
    "    - utilities: predict, apply, get_leaf_indices, leaf_bounds (data-driven),\n",
    "                 leaf_box_bounds (path constraints), score (R^2), prune, get_h\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: Optional[int] = None,\n",
    "        mse_threshold: float = 0.0,              # stop when leaf MSE_avg ≤ threshold\n",
    "        min_leaf_samples: Optional[int] = None,  # enforced post-fit only\n",
    "        ccp_alpha: float = 0.0,                  # default no pruning at fit()\n",
    "        random_state: Optional[int] = None,\n",
    "        min_improvement: float = 0.0             # minimal SSE reduction required to split\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.mse_threshold = float(mse_threshold)\n",
    "        self.min_leaf_samples = int(min_leaf_samples) if min_leaf_samples is not None else 0\n",
    "        self.ccp_alpha = float(ccp_alpha)\n",
    "        self.random_state = random_state\n",
    "        self.min_improvement = float(min_improvement)\n",
    "\n",
    "        # Fitted attributes\n",
    "        self.n_features_in_: Optional[int] = None\n",
    "        self.n_outputs_: Optional[int] = None\n",
    "        self._nodes: List[_Node] = []\n",
    "        self._root: Optional[int] = None\n",
    "        self._fitted_X: Optional[np.ndarray] = None\n",
    "        self._fitted_y: Optional[np.ndarray] = None\n",
    "\n",
    "        # Per-leaf linear models from constrained optimization: leaf_id -> dict(M, m0, h, solver)\n",
    "        self._leaf_models: Dict[int, Dict[str, Any]] = {}\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Public API\n",
    "    # ---------------------------\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        self._validate_X_y(X, y)\n",
    "        n_samples = X.shape[0]\n",
    "        idx = np.arange(n_samples, dtype=np.int64)\n",
    "\n",
    "        self._nodes = []\n",
    "        self._root = self._build_node(X, y, idx, depth=0)\n",
    "        self._assign_leaf_ids()\n",
    "\n",
    "        # Optional pruning immediately after fit if ccp_alpha > 0\n",
    "        if self.ccp_alpha > 0.0:\n",
    "            self.prune(self.ccp_alpha)\n",
    "\n",
    "        # Enforce min_leaf_samples post-fit without affecting split decisions\n",
    "        if self.min_leaf_samples > 0:\n",
    "            self._enforce_min_leaf_samples()\n",
    "\n",
    "        # Re-assign leaf ids after any pruning\n",
    "        self._assign_leaf_ids()\n",
    "\n",
    "        # Cache training data (useful for utilities)\n",
    "        self._fitted_X = X.copy()\n",
    "        self._fitted_y = y.copy()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        self._check_fitted()\n",
    "        X = self._validate_X_only(X)\n",
    "        preds = np.zeros((X.shape[0], self.n_outputs_), dtype=float)\n",
    "        for i in range(X.shape[0]):\n",
    "            node_idx = self._traverse(self._root, X[i])\n",
    "            node = self._nodes[node_idx]\n",
    "            preds[i] = node.value\n",
    "        return preds\n",
    "\n",
    "    def apply(self, X: np.ndarray) -> np.ndarray:\n",
    "        self._check_fitted()\n",
    "        X = self._validate_X_only(X)\n",
    "        leaf_ids = np.empty(X.shape[0], dtype=np.int64)\n",
    "        for i in range(X.shape[0]):\n",
    "            node_idx = self._traverse(self._root, X[i])\n",
    "            leaf_ids[i] = self._nodes[node_idx].leaf_id\n",
    "        return leaf_ids\n",
    "\n",
    "    def get_leaf_indices(self, X: Optional[np.ndarray] = None) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Returns mapping leaf_id -> sample indices that fall into that leaf.\n",
    "        If X is None, uses the training data indices.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        if X is None:\n",
    "            X = self._fitted_X\n",
    "            indices = np.arange(X.shape[0], dtype=np.int64)\n",
    "        else:\n",
    "            X = self._validate_X_only(X)\n",
    "            indices = np.arange(X.shape[0], dtype=np.int64)\n",
    "\n",
    "        leaf_ids = self.apply(X)\n",
    "        mapping: Dict[int, List[int]] = {}\n",
    "        for i, lid in enumerate(leaf_ids):\n",
    "            mapping.setdefault(int(lid), []).append(int(indices[i]))\n",
    "        return {lid: np.array(idxs, dtype=np.int64) for lid, idxs in mapping.items()}\n",
    "\n",
    "    def leaf_bounds(self, X: Optional[np.ndarray] = None) -> Dict[int, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Data-driven bounds: for each leaf, returns min/max for each feature among samples in that leaf.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        if X is None:\n",
    "            X = self._fitted_X\n",
    "        X = self._validate_X_only(X)\n",
    "\n",
    "        mapping = self.get_leaf_indices(X)\n",
    "        bounds = {}\n",
    "        for lid, idxs in mapping.items():\n",
    "            Xi = X[idxs]\n",
    "            bounds[lid] = {\n",
    "                \"min\": Xi.min(axis=0),\n",
    "                \"max\": Xi.max(axis=0),\n",
    "            }\n",
    "        return bounds\n",
    "\n",
    "    def leaf_box_bounds(self, X: Optional[np.ndarray] = None) -> Dict[int, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Returns path-based box constraints for each leaf, refined by actual data bounds.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        if X is None:\n",
    "            X = self._fitted_X\n",
    "        X = self._validate_X_only(X)\n",
    "        leaf_indices = self.get_leaf_indices(X)\n",
    "    \n",
    "        bounds = {}\n",
    "    \n",
    "        def dfs(nid: int, path: List[Tuple[int, float, str]]):\n",
    "            node = self._nodes[nid]\n",
    "            if node.is_leaf:\n",
    "                lid = node.leaf_id\n",
    "                idxs = leaf_indices.get(lid, [])\n",
    "                if len(idxs) == 0:\n",
    "                    return\n",
    "                X_leaf = X[idxs]\n",
    "                lower = X_leaf.min(axis=0)\n",
    "                upper = X_leaf.max(axis=0)\n",
    "                for f, thr, direction in path:\n",
    "                    if direction == \"left\":\n",
    "                        upper[f] = min(upper[f], thr)\n",
    "                    else:\n",
    "                        lower[f] = max(lower[f], np.nextafter(thr, np.inf))\n",
    "                bounds[lid] = {\"lower\": lower, \"upper\": upper}\n",
    "                return\n",
    "            dfs(node.left, path + [(node.feature, node.threshold, \"left\")])\n",
    "            dfs(node.right, path + [(node.feature, node.threshold, \"right\")])\n",
    "    \n",
    "        dfs(self._root, [])\n",
    "        return bounds\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Multi-output R^2 averaged across outputs.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        X = self._validate_X_only(X)\n",
    "        y = self._validate_y_only(y)\n",
    "        y_pred = self.predict(X)\n",
    "        y_mean = y.mean(axis=0)\n",
    "        ss_res = ((y - y_pred) ** 2).sum(axis=0)\n",
    "        ss_tot = ((y - y_mean) ** 2).sum(axis=0)\n",
    "        valid = ss_tot > 0\n",
    "        if not np.any(valid):\n",
    "            return 1.0\n",
    "        r2_per_output = np.ones(self.n_outputs_, dtype=float)\n",
    "        r2_per_output[valid] = 1.0 - (ss_res[valid] / ss_tot[valid])\n",
    "        return float(r2_per_output.mean())\n",
    "\n",
    "    def prune(self, ccp_alpha: float):\n",
    "        \"\"\"\n",
    "        Cost-complexity post-pruning. Prunes all internal nodes whose g_alpha ≤ ccp_alpha.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        alpha = float(ccp_alpha)\n",
    "        if alpha <= 0.0:\n",
    "            return\n",
    "\n",
    "        changed = True\n",
    "        while changed:\n",
    "            _, _, prunable = self._compute_ccp_alphas(self._root)\n",
    "            to_prune = [nid for (nid, g) in prunable if g <= alpha]\n",
    "            changed = len(to_prune) > 0\n",
    "            for nid in to_prune:\n",
    "                self._prune_subtree_to_leaf(nid)\n",
    "        self._assign_leaf_ids()\n",
    "\n",
    "    def fit_leaf_optimizers(\n",
    "        self,\n",
    "        X: Optional[np.ndarray] = None,\n",
    "        y: Optional[np.ndarray] = None,\n",
    "        optimizer: str = \"cvxpy\",  # \"cvxpy\" or \"gurobi\"\n",
    "        gurobi_params: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train constrained optimization model on each leaf using samples that reach that leaf.\n",
    "        Stores per-leaf M, m0, and h. Use predict_with_optimizers() to predict.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        if X is None:\n",
    "            X = self._fitted_X\n",
    "        if y is None:\n",
    "            y = self._fitted_y\n",
    "        X = self._validate_X_only(X)\n",
    "        y = self._validate_y_only(y)\n",
    "\n",
    "        leaf_to_indices = self.get_leaf_indices(X)\n",
    "        self._leaf_models = {}\n",
    "\n",
    "        for lid, idxs in leaf_to_indices.items():\n",
    "            if idxs.size == 0:\n",
    "                continue\n",
    "            X_leaf = X[idxs]\n",
    "            y_leaf = y[idxs]\n",
    "            if optimizer.lower() == \"cvxpy\":\n",
    "                if cp is None:\n",
    "                    raise ImportError(\"cvxpy is not available. Install cvxpy or choose optimizer='gurobi'.\")\n",
    "                M, m0, h = self._constrained_optimization_cvxpy(X_leaf, y_leaf)\n",
    "                solver_name = \"cvxpy\"\n",
    "            elif optimizer.lower() == \"gurobi\":\n",
    "                if gp is None or GRB is None:\n",
    "                    raise ImportError(\"gurobi is not available. Install gurobipy or choose optimizer='cvxpy'.\")\n",
    "                M, m0, h = self._constrained_optimization_gurobi(X_leaf, y_leaf, gurobi_params)\n",
    "                solver_name = \"gurobi\"\n",
    "            else:\n",
    "                raise ValueError(\"optimizer must be 'cvxpy' or 'gurobi'.\")\n",
    "\n",
    "            self._leaf_models[int(lid)] = {\"M\": M, \"m0\": m0, \"h\": float(h), \"solver\": solver_name}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_with_optimizers(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using per-leaf linear models (M, m0). Falls back to tree mean if a leaf has no model.\n",
    "        \"\"\"\n",
    "        self._check_fitted()\n",
    "        X = self._validate_X_only(X)\n",
    "        y_pred = np.zeros((X.shape[0], self.n_outputs_), dtype=float)\n",
    "        leaf_ids = self.apply(X)\n",
    "        for i, lid in enumerate(leaf_ids):\n",
    "            mdl = self._leaf_models.get(int(lid))\n",
    "            if mdl is not None and mdl[\"M\"] is not None and mdl[\"m0\"] is not None:\n",
    "                y_pred[i] = X[i] @ mdl[\"M\"].T + mdl[\"m0\"]\n",
    "            else:\n",
    "                node_idx = self._leaf_node_from_leaf_id(int(lid))\n",
    "                y_pred[i] = self._nodes[node_idx].value\n",
    "        return y_pred\n",
    "\n",
    "    def get_h(self) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Returns mapping leaf_id -> h from the constrained optimization.\n",
    "        \"\"\"\n",
    "        return {int(lid): float(v[\"h\"]) for lid, v in self._leaf_models.items() if \"h\" in v}\n",
    "\n",
    "    # ---------------------------\n",
    "    # Building and splitting\n",
    "    # ---------------------------\n",
    "\n",
    "    def _build_node(self, X: np.ndarray, y: np.ndarray, idx: np.ndarray, depth: int) -> int:\n",
    "        node_id = len(self._nodes)\n",
    "        node = _Node(depth=depth)\n",
    "        self._nodes.append(node)\n",
    "\n",
    "        # Stats for this node\n",
    "        Y = y[idx]\n",
    "        n_node = Y.shape[0]\n",
    "        sum_y = Y.sum(axis=0)\n",
    "        sum_y2 = float((Y ** 2).sum())\n",
    "        node.n_samples = n_node\n",
    "        node.sum_y = sum_y\n",
    "        node.sum_y2 = sum_y2\n",
    "        node.value = sum_y / max(n_node, 1)\n",
    "    \n",
    "        # Compute NRMSE for stopping\n",
    "        y_pred = np.tile(node.value, (n_node, 1))\n",
    "        y_range = np.max(Y) - np.min(Y)\n",
    "        if y_range != 0:\n",
    "            nrmse = np.sqrt(np.mean((Y - y_pred) ** 2)) / y_range\n",
    "        else:\n",
    "            nrmse = np.sqrt(np.sum((Y - y_pred) ** 2) / (n_node * self.n_outputs_))\n",
    "    \n",
    "        stop_by_depth = (self.max_depth is not None and depth >= self.max_depth)\n",
    "        if n_node <= 1 or stop_by_depth or nrmse <= self.mse_threshold:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "        \n",
    "        # Find best split\n",
    "        best = self._best_split(X, y, idx, sum_y, sum_y2, n_node)\n",
    "        if best is None:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "\n",
    "        feat, thr, left_idx, right_idx, sse_left, sse_right = best\n",
    "        parent_sse = sse\n",
    "        gain = parent_sse - (sse_left + sse_right)\n",
    "        if gain <= self.min_improvement:\n",
    "            node.is_leaf = True\n",
    "            return node_id\n",
    "\n",
    "        # Create children\n",
    "        node.is_leaf = False\n",
    "        node.feature = int(feat)\n",
    "        node.threshold = float(thr)\n",
    "        node.left = self._build_node(X, y, left_idx, depth + 1)\n",
    "        node.right = self._build_node(X, y, right_idx, depth + 1)\n",
    "        return node_id\n",
    "\n",
    "    def _best_split(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        idx: np.ndarray,\n",
    "        sum_y: np.ndarray,\n",
    "        sum_y2: float,\n",
    "        n_node: int\n",
    "    ):\n",
    "        X_node = X[idx]                                  # (n_node, n_features)\n",
    "        Y_node = y[idx]                                  # (n_node, n_outputs)\n",
    "        total_sum_y = sum_y\n",
    "        total_sum_y2 = sum_y2\n",
    "\n",
    "        best_feat = None\n",
    "        best_thr = None\n",
    "        best_sse_left = None\n",
    "        best_sse_right = None\n",
    "        best_left_idx = None\n",
    "        best_right_idx = None\n",
    "        parent_sse = self._sse(total_sum_y, total_sum_y2, n_node)\n",
    "\n",
    "        # For each feature, compute optimal split via cumulative sums\n",
    "        for f in range(self.n_features_in_):\n",
    "            x = X_node[:, f]\n",
    "            order = np.argsort(x, kind='mergesort')      # stable sort\n",
    "            x_sorted = x[order]\n",
    "            Y_sorted = Y_node[order]                     # (n_node, n_outputs)\n",
    "\n",
    "            # Valid split positions where feature value changes\n",
    "            diffs = x_sorted[1:] - x_sorted[:-1]\n",
    "            valid = diffs != 0.0\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "\n",
    "            # Cumulative sums for SSE computations\n",
    "            csum_y = np.cumsum(Y_sorted, axis=0)                       # (n_node, n_outputs)\n",
    "            row_sq = np.einsum('ij,ij->i', Y_sorted, Y_sorted)         # (n_node,)\n",
    "            csum_y2 = np.cumsum(row_sq)                                 # (n_node,)\n",
    "\n",
    "            split_positions = np.nonzero(valid)[0]  # indices i where split is between i and i+1\n",
    "\n",
    "            left_n = (split_positions + 1).astype(np.int64)\n",
    "            right_n = n_node - left_n\n",
    "\n",
    "            left_sum_y = csum_y[split_positions]                        # (m, n_outputs)\n",
    "            right_sum_y = total_sum_y - left_sum_y                      # (m, n_outputs)\n",
    "            left_sum_y2 = csum_y2[split_positions]                      # (m,)\n",
    "            right_sum_y2 = total_sum_y2 - left_sum_y2                   # (m,)\n",
    "\n",
    "            # SSE for left/right: SSE = sum(y^2) - sum(y)^2 / n\n",
    "            left_sse = left_sum_y2 - np.sum(left_sum_y ** 2, axis=1) / left_n\n",
    "            right_sse = right_sum_y2 - np.sum(right_sum_y ** 2, axis=1) / right_n\n",
    "            total_sse_after = left_sse + right_sse\n",
    "\n",
    "            # Best position for this feature\n",
    "            best_pos = int(np.argmin(total_sse_after))\n",
    "            candidate_sse = float(total_sse_after[best_pos])\n",
    "            if candidate_sse >= parent_sse:\n",
    "                continue  # no gain\n",
    "\n",
    "            # Candidate threshold: midpoint between two adjacent values\n",
    "            i = split_positions[best_pos]\n",
    "            thr = 0.5 * (x_sorted[i] + x_sorted[i + 1])\n",
    "\n",
    "            # Derive indices for children (on original node data)\n",
    "            mask_left = x <= thr\n",
    "            left_idx = idx[mask_left]\n",
    "            right_idx = idx[~mask_left]\n",
    "            if left_idx.size == 0 or right_idx.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Store if overall best\n",
    "            if best_thr is None or candidate_sse < (best_sse_left + best_sse_right):\n",
    "                best_feat = f\n",
    "                best_thr = thr\n",
    "                best_sse_left = float(left_sse[best_pos])\n",
    "                best_sse_right = float(right_sse[best_pos])\n",
    "                best_left_idx = left_idx\n",
    "                best_right_idx = right_idx\n",
    "\n",
    "        if best_thr is None:\n",
    "            return None\n",
    "        return best_feat, best_thr, best_left_idx, best_right_idx, best_sse_left, best_sse_right\n",
    "\n",
    "    # ---------------------------\n",
    "    # Pruning helpers (cost-complexity)\n",
    "    # ---------------------------\n",
    "\n",
    "    def _compute_ccp_alphas(self, nid: int) -> Tuple[float, int, List[Tuple[int, float]]]:\n",
    "        node = self._nodes[nid]\n",
    "        prunable: List[Tuple[int, float]] = []\n",
    "        if node.is_leaf:\n",
    "            R_T = self._node_impurity_as_leaf(node)\n",
    "            return R_T, 1, prunable\n",
    "\n",
    "        # Recurse\n",
    "        R_left, L_left, P_left = self._compute_ccp_alphas(node.left)\n",
    "        R_right, L_right, P_right = self._compute_ccp_alphas(node.right)\n",
    "        prunable.extend(P_left)\n",
    "        prunable.extend(P_right)\n",
    "\n",
    "        R_T = R_left + R_right\n",
    "        L_T = L_left + L_right\n",
    "\n",
    "        # If we collapse node to a leaf:\n",
    "        R_t = self._node_impurity_as_leaf(node)\n",
    "        g = (R_t - R_T) / (L_T - 1.0) if L_T > 1 else np.inf\n",
    "        node._g_alpha = g\n",
    "        prunable.append((nid, g))\n",
    "        return R_T, L_T, prunable\n",
    "\n",
    "    def _prune_subtree_to_leaf(self, nid: int):\n",
    "        node = self._nodes[nid]\n",
    "        node.is_leaf = True\n",
    "        node.left = None\n",
    "        node.right = None\n",
    "        node.feature = -1\n",
    "        node.threshold = 0.0\n",
    "        node._g_alpha = None\n",
    "\n",
    "    def _node_impurity_as_leaf(self, node: _Node) -> float:\n",
    "        n = node.n_samples\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        sse = self._sse(node.sum_y, node.sum_y2, n)\n",
    "        # Use SSE (not averaged) to maintain additivity across subtree\n",
    "        return sse\n",
    "\n",
    "    def _enforce_min_leaf_samples(self):\n",
    "        if self.min_leaf_samples <= 0:\n",
    "            return\n",
    "\n",
    "        def postorder(nid: int) -> int:\n",
    "            node = self._nodes[nid]\n",
    "            if node.is_leaf:\n",
    "                return node.n_samples\n",
    "            ln = postorder(node.left)\n",
    "            rn = postorder(node.right)\n",
    "\n",
    "            left_node = self._nodes[node.left]\n",
    "            right_node = self._nodes[node.right]\n",
    "            need_prune = False\n",
    "            if left_node.is_leaf and left_node.n_samples < self.min_leaf_samples:\n",
    "                need_prune = True\n",
    "            if right_node.is_leaf and right_node.n_samples < self.min_leaf_samples:\n",
    "                need_prune = True\n",
    "\n",
    "            if need_prune:\n",
    "                self._prune_subtree_to_leaf(nid)\n",
    "                return node.n_samples\n",
    "            return ln + rn\n",
    "\n",
    "        postorder(self._root)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Per-leaf constrained optimization\n",
    "    # ---------------------------\n",
    "\n",
    "    def _constrained_optimization_cvxpy(self, X_leaf: np.ndarray, y_leaf: np.ndarray):\n",
    "        n_samples, n_features = X_leaf.shape\n",
    "        n_outputs = y_leaf.shape[1]\n",
    "\n",
    "        M = cp.Variable((n_outputs, n_features))\n",
    "        m0 = cp.Variable((n_outputs,))\n",
    "        h = cp.Variable(nonneg=True)\n",
    "\n",
    "        prediction = X_leaf @ M.T + m0\n",
    "        constraint_expr = cp.sum_squares(prediction - y_leaf)\n",
    "        objective = cp.Minimize(h)\n",
    "        constraints = [constraint_expr <= h]\n",
    "\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        try:\n",
    "            prob.solve(solver=cp.SCS, verbose=False)\n",
    "        except Exception:\n",
    "            prob.solve(verbose=False)\n",
    "\n",
    "        Mv = M.value if M.value is not None else None\n",
    "        m0v = m0.value if m0.value is not None else None\n",
    "        hv = h.value if h.value is not None else np.inf\n",
    "        return Mv, m0v, float(hv)\n",
    "\n",
    "    def _constrained_optimization_gurobi(\n",
    "        self,\n",
    "        X_leaf: np.ndarray,\n",
    "        y_leaf: np.ndarray,\n",
    "        gurobi_params: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        n_samples, n_features = X_leaf.shape\n",
    "        n_outputs = y_leaf.shape[1]\n",
    "\n",
    "        model = gp.Model(\"constrained_optimization\")\n",
    "        model.setParam(\"OutputFlag\", 0)\n",
    "        if gurobi_params:\n",
    "            for k, v in gurobi_params.items():\n",
    "                model.setParam(k, v)\n",
    "\n",
    "        # Decision variables\n",
    "        M = model.addVars(n_outputs, n_features, lb=-GRB.INFINITY, name=\"M\")\n",
    "        m0 = model.addVars(n_outputs, lb=-GRB.INFINITY, name=\"m0\")\n",
    "        h = model.addVar(lb=0.0, name=\"h\")\n",
    "\n",
    "        # Residuals squared sum\n",
    "        quad_expr = gp.QuadExpr()\n",
    "        for i in range(n_samples):\n",
    "            for k in range(n_outputs):\n",
    "                expr = m0[k]\n",
    "                for j in range(n_features):\n",
    "                    expr = expr + M[k, j] * float(X_leaf[i, j])\n",
    "                diff = expr - float(y_leaf[i, k])\n",
    "                quad_expr.add(diff * diff)\n",
    "\n",
    "        model.addQConstr(quad_expr <= h, name=\"residual_bound\")\n",
    "        model.setObjective(h, GRB.MINIMIZE)\n",
    "        model.optimize()\n",
    "\n",
    "        if model.status in [GRB.OPTIMAL, GRB.SUBOPTIMAL] or model.SolCount > 0:\n",
    "            M_val = np.array([[M[k, j].X for j in range(n_features)] for k in range(n_outputs)], dtype=float)\n",
    "            m0_val = np.array([m0[k].X for k in range(n_outputs)], dtype=float)\n",
    "            h_val = float(h.X)\n",
    "        else:\n",
    "            M_val, m0_val, h_val = None, None, np.inf\n",
    "\n",
    "        return M_val, m0_val, h_val\n",
    "\n",
    "    # ---------------------------\n",
    "    # Traversal and utilities\n",
    "    # ---------------------------\n",
    "\n",
    "    def _assign_leaf_ids(self):\n",
    "        counter = 0\n",
    "\n",
    "        def dfs(nid: int):\n",
    "            nonlocal counter\n",
    "            node = self._nodes[nid]\n",
    "            if node.is_leaf:\n",
    "                node.leaf_id = counter\n",
    "                counter += 1\n",
    "            else:\n",
    "                dfs(node.left)\n",
    "                dfs(node.right)\n",
    "\n",
    "        dfs(self._root)\n",
    "\n",
    "    def _leaf_node_from_leaf_id(self, leaf_id: int) -> int:\n",
    "        for i, node in enumerate(self._nodes):\n",
    "            if node.is_leaf and node.leaf_id == leaf_id:\n",
    "                return i\n",
    "        raise KeyError(f\"Leaf id {leaf_id} not found.\")\n",
    "\n",
    "    def _traverse(self, nid: int, x: np.ndarray) -> int:\n",
    "        node = self._nodes[nid]\n",
    "        while not node.is_leaf:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                nid = node.left\n",
    "            else:\n",
    "                nid = node.right\n",
    "            node = self._nodes[nid]\n",
    "        return nid\n",
    "\n",
    "    @staticmethod\n",
    "    def _sse(sum_y: np.ndarray, sum_y2: float, n: int) -> float:\n",
    "        if n <= 0:\n",
    "            return 0.0\n",
    "        # SSE across outputs = sum(y^2) - sum(y)^2 / n\n",
    "        return float(sum_y2 - float(np.sum(sum_y ** 2)) / n)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Validation and checks\n",
    "    # ---------------------------\n",
    "\n",
    "    def _validate_X_y(self, X: np.ndarray, y: np.ndarray):\n",
    "        if not isinstance(X, np.ndarray) or not isinstance(y, np.ndarray):\n",
    "            raise TypeError(\"X and y must be NumPy arrays.\")\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"X must be 2D with shape (n_samples, n_features).\")\n",
    "        if y.ndim != 2:\n",
    "            raise ValueError(\"y must be 2D with shape (n_samples, n_targets).\")\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"X and y must have the same number of samples.\")\n",
    "        if not np.issubdtype(X.dtype, np.number) or not np.issubdtype(y.dtype, np.number):\n",
    "            raise TypeError(\"X and y must be numeric.\")\n",
    "        if not np.isfinite(X).all() or not np.isfinite(y).all():\n",
    "            raise ValueError(\"X and y must be finite (no NaNs or infs).\")\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Ensure contiguous float arrays\n",
    "        if X.dtype != np.float64:\n",
    "            X = X.astype(np.float64, copy=False)\n",
    "        if y.dtype != np.float64:\n",
    "            y = y.astype(np.float64, copy=False)\n",
    "\n",
    "        # Store back (caller passes references)\n",
    "        # No return needed; callers already hold X, y\n",
    "\n",
    "    def _validate_X_only(self, X: np.ndarray) -> np.ndarray:\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise TypeError(\"X must be a NumPy array.\")\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"X must be 2D with shape (n_samples, n_features).\")\n",
    "        if self.n_features_in_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted yet.\")\n",
    "        if X.shape[1] != self.n_features_in_:\n",
    "            raise ValueError(f\"X has {X.shape[1]} features, expected {self.n_features_in_}.\")\n",
    "        if not np.issubdtype(X.dtype, np.number):\n",
    "            raise TypeError(\"X must be numeric.\")\n",
    "        if not np.isfinite(X).all():\n",
    "            raise ValueError(\"X must be finite (no NaNs or infs).\")\n",
    "        if X.dtype != np.float64:\n",
    "            X = X.astype(np.float64, copy=False)\n",
    "        return X\n",
    "\n",
    "    def _validate_y_only(self, y: np.ndarray) -> np.ndarray:\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise TypeError(\"y must be a NumPy array.\")\n",
    "        if y.ndim != 2:\n",
    "            raise ValueError(\"y must be 2D with shape (n_samples, n_targets).\")\n",
    "        if self.n_outputs_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted yet.\")\n",
    "        if y.shape[1] != self.n_outputs_:\n",
    "            raise ValueError(f\"y has {y.shape[1]} targets, expected {self.n_outputs_}.\")\n",
    "        if not np.issubdtype(y.dtype, np.number):\n",
    "            raise TypeError(\"y must be numeric.\")\n",
    "        if not np.isfinite(y).all():\n",
    "            raise ValueError(\"y must be finite (no NaNs or infs).\")\n",
    "        if y.dtype != np.float64:\n",
    "            y = y.astype(np.float64, copy=False)\n",
    "        return y\n",
    "\n",
    "    def _check_fitted(self):\n",
    "        if self._root is None or self.n_features_in_ is None or self.n_outputs_ is None:\n",
    "            raise RuntimeError(\"Estimator is not fitted yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323bc18-8b1d-4ba6-8aca-ad30f2e402df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b846de-cf94-44a5-b207-c40a6131f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Initialize and train the tree\n",
    "tree = CustomDecisionTreeRegressor(mse_threshold=0.5)\n",
    "\n",
    "tree.fit(X_train, y_train) \n",
    "#max_depth=5,\n",
    "#mse_threshold=0.05,\n",
    "#min_leaf_samples=10,\n",
    "#ccp_alpha=0.0,\n",
    "#random_state=42\n",
    "#tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate tree predictions\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "\n",
    "r2_tree = r2_score(y_test, y_pred_tree, multioutput='uniform_average')\n",
    "print(f\"Tree R² score: {r2_tree:.4f}\")\n",
    "\n",
    "# Fit constrained optimizers on leaves\n",
    "tree.fit_leaf_optimizers(optimizer=\"gurobi\")\n",
    "\n",
    "# Predict using leaf optimizers\n",
    "y_pred_opt = tree.predict_with_optimizers(X_test)\n",
    "r2_opt = r2_score(y_test, y_pred_opt, multioutput='uniform_average')\n",
    "print(f\"Optimizer R² score: {r2_opt:.4f}\")\n",
    "\n",
    "# Get leaf IDs and bounds\n",
    "leaf_ids = tree.apply(X_test)\n",
    "leaf_indices = tree.get_leaf_indices(X_test)\n",
    "leaf_bounds = tree.leaf_bounds(X_test)\n",
    "leaf_box_bounds = tree.leaf_box_bounds()\n",
    "leaf_h_values = tree.get_h()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Number of leaves: {len(leaf_indices)}\")\n",
    "for lid in sorted(leaf_indices):\n",
    "    print(f\"Leaf {lid}: samples={len(leaf_indices[lid])}, h={leaf_h_values.get(lid, 'N/A'):.4f}\")\n",
    "    print(f\"  Data bounds: min={leaf_bounds[lid]['min']}, max={leaf_bounds[lid]['max']}\")\n",
    "    print(f\"  Box bounds: lower={leaf_box_bounds[lid]['lower']}, upper={leaf_box_bounds[lid]['upper']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795e014-3263-4a9c-b583-cbe14c92d8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a3222-12ba-4568-9f4c-585e461ab705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0779ec38-7528-408a-bacc-15f5ad424a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 h values from constrained optimization per leaf:\n",
      "Leaf 0: h = 1505.394794\n"
     ]
    }
   ],
   "source": [
    "# Get and print h values\n",
    "h_values = tree.get_h()\n",
    "print(\"\\n📊 h values from constrained optimization per leaf:\")\n",
    "for lid in sorted(h_values):\n",
    "    print(f\"Leaf {lid}: h = {h_values[lid]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f634de8-e724-4740-915d-cf6a0aaece10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_Node(feature=-1, threshold=0.0, left=None, right=None, n_samples=249999, sum_y=array([377024.70385036, 373585.80729221,  18115.54099502, -13792.22580622]), sum_y2=1594698.9191638913, value=array([ 1.50810485,  1.49434921,  0.07246245, -0.05516912]), depth=0, is_leaf=True, leaf_id=0, _g_alpha=None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree._nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89395fa-24ca-4381-88ae-d1db74299090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ffb403a-3927-406f-a864-cea280f5a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def bottom_up_tree_debug(tree, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Iterate tree bottom-up, printing node info (supports multi-output).\n",
    "    \"\"\"\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    node_count = tree.tree_.node_count\n",
    "\n",
    "    # Step 1: assign leaf indices for all samples\n",
    "    sample_leaves = tree.apply(X_train)\n",
    "    node_indices = {i: np.where(sample_leaves == i)[0] for i in range(node_count)}\n",
    "\n",
    "    # Step 2: recursively collect indices for all nodes\n",
    "    def collect_indices(node):\n",
    "        left = children_left[node]\n",
    "        right = children_right[node]\n",
    "\n",
    "        if left == -1 and right == -1:\n",
    "            # Leaf: already stored\n",
    "            return node_indices[node]\n",
    "\n",
    "        # Internal node: collect from children\n",
    "        left_indices = collect_indices(left)\n",
    "        right_indices = collect_indices(right)\n",
    "        combined = np.concatenate([left_indices, right_indices])\n",
    "        node_indices[node] = combined\n",
    "        return combined\n",
    "\n",
    "    collect_indices(0)  # populate all nodes\n",
    "\n",
    "    # Step 3: Bottom-up traversal\n",
    "    def bottom_up(node):\n",
    "        left = children_left[node]\n",
    "        right = children_right[node]\n",
    "\n",
    "        # Process children first\n",
    "        if left != -1:\n",
    "            bottom_up(left)\n",
    "        if right != -1:\n",
    "            bottom_up(right)\n",
    "\n",
    "        indices = node_indices[node]\n",
    "        node_value = tree.tree_.value[node].flatten()  # may be >1D if multi-output\n",
    "\n",
    "        # Compute error properly for multi-output\n",
    "        if len(indices) > 0:\n",
    "            preds = np.tile(node_value, (len(indices), 1))  # repeat value for samples\n",
    "            true_vals = y_train[indices]\n",
    "            error = np.mean(np.sum((true_vals - preds) ** 2, axis=1))\n",
    "        else:\n",
    "            error = np.nan\n",
    "\n",
    "        print(f\"Node index: {node}\")\n",
    "        print(f\"Training indices on node: {indices}\")\n",
    "        print(f\"Node value: {node_value}\")\n",
    "        print(f\"MSE error at node: {error:.4f}\\n\")\n",
    "\n",
    "    bottom_up(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9d8cc65-b761-4d93-8297-c72630500ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node index: 3\n",
      "Training indices on node: [     5      9     12 ... 449972 449994 449998]\n",
      "Node value: [ 0.55406066  0.65800726 -0.3498799  -0.03258353]\n",
      "MSE error at node: 0.6105\n",
      "\n",
      "Node index: 4\n",
      "Training indices on node: [     6      7     17 ... 449990 449993 449997]\n",
      "Node value: [ 0.64185204  0.65272199  0.53929005 -0.02492924]\n",
      "MSE error at node: 0.6070\n",
      "\n",
      "Node index: 2\n",
      "Training indices on node: [     5      9     12 ... 449990 449993 449997]\n",
      "Node value: [ 0.59770144  0.65537997  0.0921233  -0.02877861]\n",
      "MSE error at node: 0.8083\n",
      "\n",
      "Node index: 6\n",
      "Training indices on node: [    11     16     29 ... 449980 449988 449995]\n",
      "Node value: [ 1.73530217  0.772283    0.08735064 -0.49267212]\n",
      "MSE error at node: 0.6963\n",
      "\n",
      "Node index: 7\n",
      "Training indices on node: [     2      3     14 ... 449984 449986 449991]\n",
      "Node value: [1.73734368 0.8609972  0.09517587 0.3965426 ]\n",
      "MSE error at node: 0.7008\n",
      "\n",
      "Node index: 5\n",
      "Training indices on node: [    11     16     29 ... 449984 449986 449991]\n",
      "Node value: [ 1.73632069  0.81654309  0.0912547  -0.04903711]\n",
      "MSE error at node: 0.8982\n",
      "\n",
      "Node index: 1\n",
      "Training indices on node: [     5      9     12 ... 449984 449986 449991]\n",
      "Node value: [ 1.17238319  0.73672192  0.0916849  -0.03900344]\n",
      "MSE error at node: 1.1844\n",
      "\n",
      "Node index: 10\n",
      "Training indices on node: [    13     34     35 ... 449983 449987 449992]\n",
      "Node value: [ 1.26137088  2.10769694  0.08370144 -0.4950596 ]\n",
      "MSE error at node: 0.7171\n",
      "\n",
      "Node index: 11\n",
      "Training indices on node: [     4     19     41 ... 449974 449975 449981]\n",
      "Node value: [1.26651072 2.19485703 0.09257358 0.39060973]\n",
      "MSE error at node: 0.7174\n",
      "\n",
      "Node index: 9\n",
      "Training indices on node: [    13     34     35 ... 449974 449975 449981]\n",
      "Node value: [ 1.26396926  2.1517596   0.08818664 -0.04732086]\n",
      "MSE error at node: 0.9153\n",
      "\n",
      "Node index: 13\n",
      "Training indices on node: [     1      8     25 ... 449979 449982 449985]\n",
      "Node value: [ 2.35754923  2.31422269 -0.41909957 -0.10431474]\n",
      "MSE error at node: 0.6219\n",
      "\n",
      "Node index: 14\n",
      "Training indices on node: [     0     10     15 ... 449962 449989 449996]\n",
      "Node value: [ 2.4415775   2.31611743  0.46952388 -0.0928135 ]\n",
      "MSE error at node: 0.6219\n",
      "\n",
      "Node index: 12\n",
      "Training indices on node: [     1      8     25 ... 449962 449989 449996]\n",
      "Node value: [ 2.39948043  2.31516819  0.02433514 -0.09857547]\n",
      "MSE error at node: 0.8211\n",
      "\n",
      "Node index: 8\n",
      "Training indices on node: [    13     34     35 ... 449962 449989 449996]\n",
      "Node value: [ 1.83383455  2.2337675   0.05614226 -0.07304339]\n",
      "MSE error at node: 1.1987\n",
      "\n",
      "Node index: 0\n",
      "Training indices on node: [     5      9     12 ... 449962 449989 449996]\n",
      "Node value: [ 1.50624636  1.49234571  0.07374499 -0.05618488]\n",
      "MSE error at node: 1.8618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tree = DecisionTreeRegressor(max_depth=3).fit(X_train, y_train)\n",
    "bottom_up_tree_debug(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a7ee7-5bc4-4fb1-9599-dfd0a0361a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051eb6e-e222-4a23-994e-c12b96dbac0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd1cb0-638b-4047-9ddf-4b488ec949cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadbd9a-14b3-4e93-b1e3-e3ae4e76800a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236cf8d-5923-4b60-a257-f7723d0c6c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4f721-deff-400a-a116-0e2b295bd6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783089e-d60c-439f-bfb4-2c6a946f3fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f675fd-e5b7-4016-8706-f6ddaa8c794f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214b5a02-d626-4d82-9316-0be545f74fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_prune_COF_tree_v2(X_train, y_train, X_test=None, y_test=None, \n",
    "                                initial_tree_params=None, optimizer=\"gurobi\", \n",
    "                                alpha=1e-6, h_min=0, ignore_h=False, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Train, build COF models, prune in parallel, and print stats.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Train a DecisionTreeRegressor, build COF models for leaves, and prune the tree in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : np.ndarray\n",
    "        Training data\n",
    "    initial_tree_params : dict\n",
    "        Parameters to initialize DecisionTreeRegressor\n",
    "    optimizer : str\n",
    "        COF optimizer (\"gurobi\", \"gurobi_MSE\", etc.)\n",
    "    alpha : float\n",
    "        Penalty for number of leaves\n",
    "    h_min : float\n",
    "        Minimum allowed h for pruning\n",
    "    ignore_h : bool\n",
    "        If True, h is ignored in pruning\n",
    "    n_jobs : int\n",
    "        Number of parallel jobs for leaf computation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tree : DecisionTreeRegressor\n",
    "        The pruned tree\n",
    "    COF_model_tree : list of dict\n",
    "        COF models (updated after pruning)\n",
    "    \"\"\"\n",
    "    # 1️⃣ Train initial tree\n",
    "    if initial_tree_params is None:\n",
    "        initial_tree_params = {\"max_depth\": 5}\n",
    "    tree = DecisionTreeRegressor(**initial_tree_params)\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # 2️⃣ Build COF models for leaves\n",
    "    COF_model_tree = train_COF_on_leaves_parallel(X_train, y_train, tree, optimizer=optimizer, n_jobs=n_jobs)\n",
    "\n",
    "    # 3️⃣ Leaf info mapping\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    leaf_nodes = np.where(children_left == -1)[0]\n",
    "    leaf_h_dict = {leaf: COF_model_tree[i]['CO_Model']['h'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_indices_dict = {leaf: COF_model_tree[i]['indices'] for i, leaf in enumerate(leaf_nodes)}\n",
    "    leaf_COFS_dict = {leaf: COF_model_tree[i] for i, leaf in enumerate(leaf_nodes)}\n",
    "\n",
    "    # Helper function to compute h dynamically\n",
    "    def compute_h(indices):\n",
    "        if ignore_h:\n",
    "            return 0\n",
    "        if optimizer == \"gurobi\":\n",
    "            _, _, h = constrained_optimization_gurobi(X_train[indices], y_train[indices])\n",
    "        elif optimizer == \"gurobi_MSE\":\n",
    "            _, _, h = constrained_optimization_MSE_gurobi(X_train[indices], y_train[indices])\n",
    "        else:\n",
    "            _, _, h = constrained_optimization(X_train[indices], y_train[indices])\n",
    "        return max(h, h_min)\n",
    "\n",
    "    # -------------------------------\n",
    "    # 4️⃣ Parallelized recursive pruning\n",
    "    # -------------------------------\n",
    "    def prune_node(node):\n",
    "        left = children_left[node]\n",
    "        right = children_right[node]\n",
    "\n",
    "        if left == -1 and right == -1:\n",
    "            # Leaf\n",
    "            h_leaf = leaf_h_dict[node]\n",
    "            return h_leaf, 1, leaf_indices_dict[node]\n",
    "\n",
    "        # Evaluate left/right subtrees in parallel\n",
    "        results = Parallel(n_jobs=2)(\n",
    "            delayed(prune_node)(child) for child in [left, right]\n",
    "        )\n",
    "        (left_cost, left_leaves, left_indices), (right_cost, right_leaves, right_indices) = results\n",
    "\n",
    "        combined_indices = np.concatenate([left_indices, right_indices])\n",
    "        subtree_cost = left_cost + right_cost\n",
    "        subtree_leaves = left_leaves + right_leaves\n",
    "\n",
    "        h_parent = compute_h(combined_indices)\n",
    "        prune_cost = h_parent + alpha\n",
    "        prune_leaves = 1\n",
    "\n",
    "        if prune_cost <= subtree_cost:\n",
    "            # Prune children\n",
    "            children_left[node] = -1\n",
    "            children_right[node] = -1\n",
    "\n",
    "            # Update tree.value\n",
    "            tree.tree_.value[node] = np.array([[h_parent]])\n",
    "            leaf_h_dict[node] = h_parent\n",
    "            leaf_indices_dict[node] = combined_indices\n",
    "\n",
    "            leaf_COFS_dict[node] = {\n",
    "                \"leaf_id\": node,\n",
    "                \"CO_Model\": {\"h\": h_parent},\n",
    "                \"indices\": combined_indices,\n",
    "                \"no_samples\": len(combined_indices)\n",
    "            }\n",
    "            return prune_cost, prune_leaves, combined_indices\n",
    "        else:\n",
    "            return subtree_cost, subtree_leaves, combined_indices\n",
    "\n",
    "    # 5️⃣ Stats before pruning\n",
    "    num_leaves_before = len(leaf_nodes)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        nrmse_train_before = normalized_root_mean_square_error(y_train, tree.predict(X_train))\n",
    "        nrmse_test_before = normalized_root_mean_square_error(y_test, tree.predict(X_test))\n",
    "        nrmse_train_COF_before = normalized_root_mean_square_error(y_train, predict_from_COF(COF_model_tree, X_train, tree))\n",
    "        nrmse_test_COF_before = normalized_root_mean_square_error(y_test, predict_from_COF(COF_model_tree, X_test, tree))\n",
    "        print(f\"Before pruning: Leaves={num_leaves_before}, NRMSE[Tree]={nrmse_train_before:.4f}/{nrmse_test_before:.4f}, NRMSE[COF]={nrmse_train_COF_before:.4f}/{nrmse_test_COF_before:.4f}\")\n",
    "\n",
    "    # 6️⃣ Start pruning from root\n",
    "    prune_node(0)\n",
    "\n",
    "    # 7️⃣ Stats after pruning\n",
    "    COF_model_tree_pruned = list(leaf_COFS_dict.values())\n",
    "    num_leaves_after = len(COF_model_tree_pruned)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        nrmse_train_after = normalized_root_mean_square_error(y_train, tree.predict(X_train))\n",
    "        nrmse_test_after = normalized_root_mean_square_error(y_test, tree.predict(X_test))\n",
    "        nrmse_train_COF_after = normalized_root_mean_square_error(y_train, predict_from_COF(COF_model_tree_pruned, X_train, tree))\n",
    "        nrmse_test_COF_after = normalized_root_mean_square_error(y_test, predict_from_COF(COF_model_tree_pruned, X_test, tree))\n",
    "        print(f\"After pruning: Leaves={num_leaves_after}, NRMSE[Tree]={nrmse_train_after:.4f}/{nrmse_test_after:.4f}, NRMSE[COF]={nrmse_train_COF_after:.4f}/{nrmse_test_COF_after:.4f}\")\n",
    "\n",
    "    return tree, COF_model_tree_pruned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccd594c4-d8d0-4c37-a986-77ed830589d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Before pruning: Leaves=32, NRMSE[Tree]=0.0687/0.0686, NRMSE[COF]=0.0034/0.0034\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "After pruning: Leaves=32, NRMSE[Tree]=0.0687/0.0686, NRMSE[COF]=0.0034/0.0034\n"
     ]
    }
   ],
   "source": [
    "tree, COF_model =train_and_prune_COF_tree_v2(X_train, y_train, X_test=X_test, y_test=y_test, \n",
    "                                initial_tree_params=None, optimizer=\"gurobi\", \n",
    "                                alpha=2, h_min=1, ignore_h=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a7578ad-939c-4c40-becf-3c458b3ae23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.247495125548335,\n",
       " 15.970116469724417,\n",
       " 9.896257219805027e-05,\n",
       " 13.297375726471527,\n",
       " 10.063166303461312,\n",
       " 19.84039996511953,\n",
       " 0.0002915225348566648,\n",
       " 26.351826120993845,\n",
       " 19.731365798253936,\n",
       " 27.784298026201956,\n",
       " 0.020334491560324075,\n",
       " 2.8069198481649876e-05,\n",
       " 11.76965344336756,\n",
       " 12.840628849843235,\n",
       " 19.50031001173883,\n",
       " 12.95491713564067,\n",
       " 26.714420813368676,\n",
       " 19.631612981318483,\n",
       " 2.882897122440768e-05,\n",
       " 12.976188609804481,\n",
       " 15.59830223027343,\n",
       " 5.081453184122862e-05,\n",
       " 3.616854578928122e-05,\n",
       " 5.152554209046204e-05,\n",
       " 0.00012612581272515916,\n",
       " 12.577742652167915,\n",
       " 1.3682289603790343e-05,\n",
       " 3.816671606296249e-05,\n",
       " 26.894228586387467,\n",
       " 12.080145465898758,\n",
       " 0.00013950234297040176,\n",
       " 15.719675279783754]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_h_from_COF(COF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960b945-3a25-4368-aa32-168d7fe757c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b2ecff-9161-47e9-822f-ef1b4a12e98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves: 32\n",
      "Total depth of tree: 5\n",
      "Number of nodes: 63\n"
     ]
    }
   ],
   "source": [
    "numLeaves = tree.get_n_leaves()\n",
    "print(f\"Number of leaves: {tree.get_n_leaves()}\")\n",
    "print(f\"Total depth of tree: {tree.get_depth()}\")\n",
    "print(f\"Number of nodes: {tree.tree_.node_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce816d7-2264-435a-9a48-c772bf20b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pruning path\n",
    "path = tree.cost_complexity_pruning_path(X, y)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "# Train trees for each alpha\n",
    "trees = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeRegressor(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X, y)\n",
    "    trees.append(clf)\n",
    "\n",
    "# Evaluate on validation set and pick best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06771e-a5b8-4975-8ae0-d40b3ca5125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Train/Val/Test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 2. Train full tree and get pruning path\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "path = tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# 3. Train/prune with different alphas and evaluate on validation set\n",
    "val_mse = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeRegressor(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    val_mse.append(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "# 4. Find best alpha\n",
    "best_alpha = ccp_alphas[np.argmin(val_mse)]\n",
    "\n",
    "# 5. Retrain final tree on Train+Val\n",
    "X_trainval = np.vstack([X_train, X_val])\n",
    "y_trainval = np.hstack([y_train, y_val])\n",
    "\n",
    "final_tree = DecisionTreeRegressor(random_state=42, ccp_alpha=best_alpha)\n",
    "final_tree.fit(X_trainval, y_trainval)\n",
    "\n",
    "# 6. Test evaluation\n",
    "y_test_pred = final_tree.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# 7. Plot validation curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ccp_alphas, val_mse, marker=\"o\", drawstyle=\"steps-post\")\n",
    "plt.axvline(best_alpha, color=\"red\", linestyle=\"--\", label=f\"Best α = {best_alpha:.5f}\")\n",
    "plt.xlabel(\"ccp_alpha (complexity parameter)\")\n",
    "plt.ylabel(\"Validation MSE\")\n",
    "plt.title(\"Validation Curve for Cost Complexity Pruning\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c9bc36-e378-4536-9da1-4b0eed2960f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m ):\n\u001b[0;32m-> 1800\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     y_val_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_squared_error(y_val, y_val_pred)\n\u001b[0;32m---> 25\u001b[0m val_mse \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_alpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mccp_alphas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 4. Pick best alpha\u001b[39;00m\n\u001b[1;32m     28\u001b[0m best_alpha \u001b[38;5;241m=\u001b[39m ccp_alphas[np\u001b[38;5;241m.\u001b[39margmin(val_mse)]\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/parallel.py:1732\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/parallel.py:1646\u001b[0m, in \u001b[0;36mParallel._abort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(backend, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabort_everything\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n\u001b[0;32m-> 1646\u001b[0m     \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabort_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/_parallel_backends.py:725\u001b[0m, in \u001b[0;36mLokyBackend.abort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mabort_everything\u001b[39m(\u001b[38;5;28mself\u001b[39m, ensure_ready\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    724\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\"\"\"\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_ready:\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/executor.py:86\u001b[0m, in \u001b[0;36mMemmappingExecutor.terminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mterminate\u001b[39m(\u001b[38;5;28mself\u001b[39m, kill_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkill_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# on by the resource_tracker.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n",
      "File \u001b[0;32m~/ResearchTasks/Extracting_BSR_Benchmark_Neural_Abstraction/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:1333\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_manager_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m wait:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# is shutting down.\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _global_shutdown_lock:\n\u001b[0;32m-> 1333\u001b[0m         \u001b[43mexecutor_manager_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m         _threads_wakeups\u001b[38;5;241m.\u001b[39mpop(executor_manager_thread, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;66;03m# objects that use file descriptors.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 1. Train/Val/Test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 2. Get pruning path\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "path = tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# 3. Parallel training & validation\n",
    "def evaluate_alpha(ccp_alpha):\n",
    "    clf = DecisionTreeRegressor(random_state=42, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "val_mse = Parallel(n_jobs=-1)(delayed(evaluate_alpha)(alpha) for alpha in ccp_alphas)\n",
    "\n",
    "# 4. Pick best alpha\n",
    "best_alpha = ccp_alphas[np.argmin(val_mse)]\n",
    "\n",
    "# 5. Retrain final tree on Train+Val\n",
    "X_trainval = np.vstack([X_train, X_val])\n",
    "y_trainval = np.hstack([y_train, y_val])\n",
    "\n",
    "final_tree = DecisionTreeRegressor(random_state=42, ccp_alpha=best_alpha)\n",
    "final_tree.fit(X_trainval, y_trainval)\n",
    "\n",
    "# 6. Test evaluation\n",
    "y_test_pred = final_tree.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# 7. Plot validation curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ccp_alphas, val_mse, marker=\"o\", drawstyle=\"steps-post\")\n",
    "plt.axvline(best_alpha, color=\"red\", linestyle=\"--\", label=f\"Best α = {best_alpha:.5f}\")\n",
    "plt.xlabel(\"ccp_alpha (complexity parameter)\")\n",
    "plt.ylabel(\"Validation MSE\")\n",
    "plt.title(\"Validation Curve for Cost Complexity Pruning\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06b650-53ee-4c89-a8c7-578a93ba45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d00eb-e20f-4d6c-97d6-79ce5c683752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
